{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f63852-fdd5-4aea-bea0-a79aa123f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and config\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Config\n",
    "PROJECT_ROOT = Path('..')   # notebook is inside notebooks/ so parent is project-root\n",
    "DATA_PATH = PROJECT_ROOT / 'kaggle_dataset' / 'Training.csv'\n",
    "MODEL_DIR = PROJECT_ROOT / 'model'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Quick knobs (reduce if your PC is slow)\n",
    "RF_N_ESTIMATORS = 200\n",
    "GB_N_ESTIMATORS = 200\n",
    "STACK_CV = 5\n",
    "CALIBRATE_CV = 3\n",
    "SELECT_THRESHOLD = \"median\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "855bb7ac-94b5-4196-8b7b-e095fe8911b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\CSE\\Final Project Defense\\Final Project Defense (2025)\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a927500d-c341-4a73-aa7d-2f03f06a3b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>pus_filled_pimples</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "      <td>4920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.137805</td>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.162195</td>\n",
       "      <td>0.139024</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.023171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.344730</td>\n",
       "      <td>0.366417</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>0.207593</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>0.368667</td>\n",
       "      <td>0.346007</td>\n",
       "      <td>0.207593</td>\n",
       "      <td>0.207593</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>0.146539</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.150461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           itching    skin_rash  nodal_skin_eruptions  continuous_sneezing  \\\n",
       "count  4920.000000  4920.000000           4920.000000          4920.000000   \n",
       "mean      0.137805     0.159756              0.021951             0.045122   \n",
       "std       0.344730     0.366417              0.146539             0.207593   \n",
       "min       0.000000     0.000000              0.000000             0.000000   \n",
       "25%       0.000000     0.000000              0.000000             0.000000   \n",
       "50%       0.000000     0.000000              0.000000             0.000000   \n",
       "75%       0.000000     0.000000              0.000000             0.000000   \n",
       "max       1.000000     1.000000              1.000000             1.000000   \n",
       "\n",
       "         shivering       chills   joint_pain  stomach_pain      acidity  \\\n",
       "count  4920.000000  4920.000000  4920.000000   4920.000000  4920.000000   \n",
       "mean      0.021951     0.162195     0.139024      0.045122     0.045122   \n",
       "std       0.146539     0.368667     0.346007      0.207593     0.207593   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ulcers_on_tongue  ...  pus_filled_pimples   blackheads     scurring  \\\n",
       "count       4920.000000  ...         4920.000000  4920.000000  4920.000000   \n",
       "mean           0.021951  ...            0.021951     0.021951     0.021951   \n",
       "std            0.146539  ...            0.146539     0.146539     0.146539   \n",
       "min            0.000000  ...            0.000000     0.000000     0.000000   \n",
       "25%            0.000000  ...            0.000000     0.000000     0.000000   \n",
       "50%            0.000000  ...            0.000000     0.000000     0.000000   \n",
       "75%            0.000000  ...            0.000000     0.000000     0.000000   \n",
       "max            1.000000  ...            1.000000     1.000000     1.000000   \n",
       "\n",
       "       skin_peeling  silver_like_dusting  small_dents_in_nails  \\\n",
       "count   4920.000000          4920.000000           4920.000000   \n",
       "mean       0.023171             0.023171              0.023171   \n",
       "std        0.150461             0.150461              0.150461   \n",
       "min        0.000000             0.000000              0.000000   \n",
       "25%        0.000000             0.000000              0.000000   \n",
       "50%        0.000000             0.000000              0.000000   \n",
       "75%        0.000000             0.000000              0.000000   \n",
       "max        1.000000             1.000000              1.000000   \n",
       "\n",
       "       inflammatory_nails      blister  red_sore_around_nose  \\\n",
       "count         4920.000000  4920.000000           4920.000000   \n",
       "mean             0.023171     0.023171              0.023171   \n",
       "std              0.150461     0.150461              0.150461   \n",
       "min              0.000000     0.000000              0.000000   \n",
       "25%              0.000000     0.000000              0.000000   \n",
       "50%              0.000000     0.000000              0.000000   \n",
       "75%              0.000000     0.000000              0.000000   \n",
       "max              1.000000     1.000000              1.000000   \n",
       "\n",
       "       yellow_crust_ooze  \n",
       "count        4920.000000  \n",
       "mean            0.023171  \n",
       "std             0.150461  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             0.000000  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 132 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../kaggle_dataset/Training.csv\")\n",
    "# printing the dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6815e651-a1cb-4025-b0e5-9848be0c127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../kaggle_dataset/description.csv'),\n",
       " WindowsPath('../kaggle_dataset/diets.csv'),\n",
       " WindowsPath('../kaggle_dataset/medications.csv'),\n",
       " WindowsPath('../kaggle_dataset/precautions_df.csv'),\n",
       " WindowsPath('../kaggle_dataset/Symptom-severity.csv'),\n",
       " WindowsPath('../kaggle_dataset/symptoms_df.csv'),\n",
       " WindowsPath('../kaggle_dataset/Training.csv'),\n",
       " WindowsPath('../kaggle_dataset/workout_df.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: list dataset files\n",
    "list((PROJECT_ROOT / 'kaggle_dataset').glob('*.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedf7f3d-4e86-41bf-a3d1-b1e05a996a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4920, 133)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prognosis\n",
       "Fungal infection       120\n",
       "Allergy                120\n",
       "GERD                   120\n",
       "Chronic cholestasis    120\n",
       "Drug Reaction          120\n",
       "Peptic ulcer diseae    120\n",
       "AIDS                   120\n",
       "Diabetes               120\n",
       "Gastroenteritis        120\n",
       "Bronchial Asthma       120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: load Training.csv and explore\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.columns[:20]   # show first 20 columns\n",
    "df['prognosis'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4f82f3-0200-4e27-8eea-36f9b5cac325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 132 Num classes: 41\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: features and labels\n",
    "X = df.drop(columns=['prognosis'])\n",
    "y = df['prognosis']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# Save label encoder for later use in Flask\n",
    "with open(MODEL_DIR / 'label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Num features:\", X.shape[1], \"Num classes:\", len(le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8e1583-fa44-4408-95e1-d9c8fde57328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3690, 132) Test: (1230, 132)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.25, random_state=RANDOM_STATE, stratify=y_enc\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133ae5d3-d2c4-4468-9d92-ac0e5efbb53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature count: 66\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: scaler + feature selection (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature selection via RandomForest importance\n",
    "fs_est = RandomForestClassifier(n_estimators=RF_N_ESTIMATORS, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "fs_est.fit(X_train_scaled, y_train)\n",
    "\n",
    "selector = SelectFromModel(fs_est, threshold=SELECT_THRESHOLD, prefit=True)\n",
    "X_train_sel = selector.transform(X_train_scaled)\n",
    "X_test_sel = selector.transform(X_test_scaled)\n",
    "\n",
    "print(\"Selected feature count:\", X_train_sel.shape[1])\n",
    "\n",
    "# Save scaler and selector for deployment\n",
    "with open(MODEL_DIR / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(MODEL_DIR / 'selector.pkl', 'wb') as f:\n",
    "    pickle.dump(selector, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b15d19b-9af9-4453-81c0-3e77895a91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... (may take minutes)\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: define and train stacking + calibration\n",
    "base_estimators = [\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=RF_N_ESTIMATORS, random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=GB_N_ESTIMATORS, random_state=RANDOM_STATE)),\n",
    "    (\"svc\", SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "meta = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta,\n",
    "    cv=StratifiedKFold(n_splits=STACK_CV, shuffle=True, random_state=RANDOM_STATE),\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "calibrated = CalibratedClassifierCV(stack, cv=CALIBRATE_CV, method=\"isotonic\")\n",
    "\n",
    "print(\"Training... (may take minutes)\")\n",
    "calibrated.fit(X_train_sel, y_train)\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9515cc02-78a1-485c-b5bd-fa8897b3b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9911\n",
      "F1 (weighted): 0.9915\n",
      "Recall (weighted): 0.9911\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "(vertigo) Paroymsal  Positional Vertigo       1.00      1.00      1.00        30\n",
      "                                   AIDS       1.00      1.00      1.00        30\n",
      "                                   Acne       0.73      1.00      0.85        30\n",
      "                    Alcoholic hepatitis       1.00      1.00      1.00        30\n",
      "                                Allergy       1.00      0.87      0.93        30\n",
      "                              Arthritis       1.00      1.00      1.00        30\n",
      "                       Bronchial Asthma       1.00      1.00      1.00        30\n",
      "                   Cervical spondylosis       1.00      1.00      1.00        30\n",
      "                            Chicken pox       1.00      1.00      1.00        30\n",
      "                    Chronic cholestasis       1.00      1.00      1.00        30\n",
      "                            Common Cold       1.00      1.00      1.00        30\n",
      "                                 Dengue       1.00      1.00      1.00        30\n",
      "                              Diabetes        1.00      1.00      1.00        30\n",
      "           Dimorphic hemmorhoids(piles)       1.00      0.87      0.93        30\n",
      "                          Drug Reaction       1.00      1.00      1.00        30\n",
      "                       Fungal infection       1.00      1.00      1.00        30\n",
      "                                   GERD       1.00      1.00      1.00        30\n",
      "                        Gastroenteritis       1.00      1.00      1.00        30\n",
      "                           Heart attack       1.00      1.00      1.00        30\n",
      "                            Hepatitis B       1.00      1.00      1.00        30\n",
      "                            Hepatitis C       1.00      1.00      1.00        30\n",
      "                            Hepatitis D       1.00      1.00      1.00        30\n",
      "                            Hepatitis E       1.00      1.00      1.00        30\n",
      "                          Hypertension        1.00      1.00      1.00        30\n",
      "                        Hyperthyroidism       1.00      1.00      1.00        30\n",
      "                           Hypoglycemia       1.00      1.00      1.00        30\n",
      "                         Hypothyroidism       1.00      1.00      1.00        30\n",
      "                               Impetigo       1.00      1.00      1.00        30\n",
      "                               Jaundice       1.00      1.00      1.00        30\n",
      "                                Malaria       1.00      1.00      1.00        30\n",
      "                               Migraine       1.00      0.97      0.98        30\n",
      "                        Osteoarthristis       1.00      1.00      1.00        30\n",
      "           Paralysis (brain hemorrhage)       1.00      1.00      1.00        30\n",
      "                    Peptic ulcer diseae       1.00      1.00      1.00        30\n",
      "                              Pneumonia       1.00      1.00      1.00        30\n",
      "                              Psoriasis       1.00      0.93      0.97        30\n",
      "                           Tuberculosis       1.00      1.00      1.00        30\n",
      "                                Typhoid       1.00      1.00      1.00        30\n",
      "                Urinary tract infection       1.00      1.00      1.00        30\n",
      "                         Varicose veins       1.00      1.00      1.00        30\n",
      "                            hepatitis A       1.00      1.00      1.00        30\n",
      "\n",
      "                               accuracy                           0.99      1230\n",
      "                              macro avg       0.99      0.99      0.99      1230\n",
      "                           weighted avg       0.99      0.99      0.99      1230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: evaluate\n",
    "y_pred = calibrated.predict(X_test_sel)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 (weighted): {f1:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "\n",
    "# Detailed report\n",
    "report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a50f8a-6b43-4e97-9811-dea05049d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training_metrics.json, classification_report.csv, confusion_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: save metrics + reports to model/\n",
    "metrics = {\"accuracy\": float(acc), \"f1_weighted\": float(f1), \"recall_weighted\": float(recall)}\n",
    "with open(MODEL_DIR / 'training_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "pd.DataFrame(classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)).transpose().to_csv(MODEL_DIR / 'classification_report.csv')\n",
    "np.savetxt(MODEL_DIR / 'confusion_matrix.csv', confusion_matrix(y_test, y_pred), delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "print(\"Saved training_metrics.json, classification_report.csv, confusion_matrix.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7bc660f-b333-4b54-8412-e59999c87b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CustomStackedModel.pkl in model/\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: create single artifact dict and pickle (for Flask)\n",
    "artifacts = {\n",
    "    \"scaler\": scaler,\n",
    "    \"selector\": selector,\n",
    "    \"model\": calibrated,\n",
    "    \"label_encoder\": le\n",
    "}\n",
    "with open(MODEL_DIR / 'CustomStackedModel.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "print(\"Saved CustomStackedModel.pkl in model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0265ef6c-6aa1-4546-b310-e84e9c98afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo prediction (example): Migraine\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 replacement: clean demo-predict using DataFrame with same columns\n",
    "import pickle\n",
    "\n",
    "# load saved artifact\n",
    "with open(MODEL_DIR / 'CustomStackedModel.pkl','rb') as f:\n",
    "    art = pickle.load(f)\n",
    "\n",
    "scaler2 = art['scaler']\n",
    "selector2 = art['selector']\n",
    "model2 = art['model']\n",
    "le2 = art['label_encoder']\n",
    "\n",
    "# symptom column names (must match the original Training.csv column order)\n",
    "symptom_names = list(X.columns)   # X from earlier cells (DataFrame)\n",
    "\n",
    "def symptoms_to_vector(symptom_list):\n",
    "    # create a zero vector with proper column names\n",
    "    vec = pd.DataFrame(np.zeros((1, len(symptom_names))), columns=symptom_names)\n",
    "    # set 1 for present symptoms (exact string match required)\n",
    "    for s in symptom_list:\n",
    "        if s in vec.columns:\n",
    "            vec.at[0, s] = 1\n",
    "        else:\n",
    "            print(f\"Warning: symptom '{s}' not found in column names\")\n",
    "    # now transform with DataFrame (keeps feature names)\n",
    "    vec_scaled = scaler2.transform(vec)      # no warning now\n",
    "    vec_sel = selector2.transform(vec_scaled)\n",
    "    pred_enc = model2.predict(vec_sel)[0]\n",
    "    return le2.inverse_transform([pred_enc])[0]\n",
    "\n",
    "# Example usage (replace with real symptom names from your dataset)\n",
    "print(\"Demo prediction (example):\", symptoms_to_vector(['headache', 'cough']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7113856c-aa43-4d43-8a90-37b2c6570a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 (use only if short time): reduce complexity and retrain\n",
    "RF_N_ESTIMATORS = 80\n",
    "GB_N_ESTIMATORS = 80\n",
    "STACK_CV = 3\n",
    "CALIBRATE_CV = 2\n",
    "# Re-run from Cell 6 onwards to retrain faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0403d0bd-0174-4b0b-a621-b1b85e92d69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your symptoms (comma-separated):  vomiting, headache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Symptoms you entered: ['vomiting', 'headache']\n",
      "\n",
      "üîÆ Predicted Disease: Paralysis (brain hemorrhage)\n"
     ]
    }
   ],
   "source": [
    "# ==== USER INPUT PREDICTION CELL (Jupyter Notebook) ====\n",
    "\n",
    "# Load artifacts (if not already loaded)\n",
    "with open(MODEL_DIR / 'CustomStackedModel.pkl','rb') as f:\n",
    "    art = pickle.load(f)\n",
    "\n",
    "scaler2 = art['scaler']\n",
    "selector2 = art['selector']\n",
    "model2 = art['model']\n",
    "le2 = art['label_encoder']\n",
    "\n",
    "symptom_names = list(X.columns)  # X is Training.csv columns from earlier notebook cell\n",
    "\n",
    "def symptoms_to_vector(symptom_list):\n",
    "    \"\"\"\n",
    "    Convert symptom string list -> feature vector -> scaled -> selected -> prediction\n",
    "    \"\"\"\n",
    "    # Build empty vector with correct columns\n",
    "    vec = pd.DataFrame(np.zeros((1, len(symptom_names))), columns=symptom_names)\n",
    "\n",
    "    # Fill 1 for symptoms found\n",
    "    for s in symptom_list:\n",
    "        s_clean = s.strip().lower().replace(\" \", \"_\")  # basic cleaning\n",
    "        matched = None\n",
    "\n",
    "        # exact match\n",
    "        for col in symptom_names:\n",
    "            if col.lower() == s_clean:\n",
    "                matched = col\n",
    "                break\n",
    "\n",
    "        # If not found, fuzzy match (optional)\n",
    "        if matched is None:\n",
    "            from fuzzywuzzy import process\n",
    "            best_match, score = process.extractOne(s_clean, symptom_names)\n",
    "            if score > 80:   # threshold\n",
    "                matched = best_match\n",
    "\n",
    "        # Mark the symptom\n",
    "        if matched:\n",
    "            vec.at[0, matched] = 1\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Symptom not recognized: {s}\")\n",
    "\n",
    "    # Preprocess\n",
    "    vec_scaled = scaler2.transform(vec)\n",
    "    vec_sel = selector2.transform(vec_scaled)\n",
    "\n",
    "    pred_enc = model2.predict(vec_sel)[0]\n",
    "    return le2.inverse_transform([pred_enc])[0]\n",
    "\n",
    "\n",
    "# ---- TAKE USER INPUT ----\n",
    "\n",
    "user_input = input(\"Enter your symptoms (comma-separated): \")\n",
    "\n",
    "# Convert to list\n",
    "symptom_list = [s.strip() for s in user_input.split(\",\")]\n",
    "\n",
    "print(\"\\nSymptoms you entered:\", symptom_list)\n",
    "prediction = symptoms_to_vector(symptom_list)\n",
    "\n",
    "print(\"\\nüîÆ Predicted Disease:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abd786-9fe2-48fa-8f90-11dba5e17229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
